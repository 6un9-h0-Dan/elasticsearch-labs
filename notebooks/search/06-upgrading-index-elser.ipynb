{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upgrade index to use ELSER using Reindex API\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/notebooks/06-upgrading-index-elser.ipynb)\n",
    "\n",
    "Elasticsearch [Reindex API](https://elasticsearch-py.readthedocs.io/en/stable/api.html#elasticsearch.Elasticsearch.reindex) can be used when you want to move data from one index to another, update or change mapping of the index or even update data of your index. \n",
    "\n",
    "In this workbook we will see example on how to migrate your index to use ELSER model using [Reindex API with ingestion pipeline](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html#reindex-with-an-ingest-pipeline). \n",
    "\n",
    "Few scenerios that we will see in this workbook are:\n",
    "\n",
    "1. Migrating a index which doesn't have generated [`text_expansion`](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-text-expansion-query.html) field to  ELSER model `.elser_model_2` \n",
    "2. Upgrade an existing index with `.elser_model_1` to use `.elser_model_2` model\n",
    "3. Upgrade a index which use different model to use ELSER\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§° Requirements\n",
    "\n",
    "For this example, you will need:\n",
    "\n",
    "- An Elastic deployment with minimum **4GB machine learning node**\n",
    "   - We'll be using [Elastic Cloud](https://www.elastic.co/guide/en/cloud/current/ec-getting-started.html) for this example (available with a [free trial](   https://cloud.elastic.co/registration?utm_source=github&utm_content=elasticsearch-labs-notebook))\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Elastic Cloud deployment\n",
    "\n",
    "If you don't have an Elastic Cloud deployment, sign up [here](https://cloud.elastic.co/registration?utm_source=github&utm_content=elasticsearch-labs-notebook) for a free trial.\n",
    "\n",
    "- Go to the [Create deployment](https://cloud.elastic.co/deployments/create) page\n",
    "   - Under **Advanced settings**, go to **Machine Learning instances**\n",
    "   - You'll need at least **4GB** RAM per zone for this tutorial\n",
    "   - Select **Create deployment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup ELSER\n",
    "\n",
    "ELSER is a trained model by Elastic that help with performing semantic search on your data and retrieve results based on the context. \n",
    "\n",
    "To use ELSER, you must have the [appropriate subscription]() level or the trial period activated.\n",
    "\n",
    "Elasticsearch version < 8.11 supports `.elser_model_1` and from 8.11 Elastic supports `.elser_model_2` model which offers improved retrieval accuracy and faster indexing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install packages and connect with Elasticsearch Client\n",
    "\n",
    "To get started, we will need to connect to our Elastic deployment using the Python client. As we are using Elastic Cloud deployment, we will use the **Cloud ID** to identify our deployment. To find your **Cloud ID**, go to https://cloud.elastic.co/deployments and select your deployment.\n",
    "\n",
    "Next, we will install `elasticsearch` package using `pip`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install elasticsearch -qU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will import all the modules that we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from urllib.request import urlopen\n",
    "import getpass\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will instantiate the Python Elasticsearch client. For authorization,on prompt we will provide our `Cloud ID` and `password`, which would enable use us to create `Elasticsearch` instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found in the 'Manage Deployment' page\n",
    "CLOUD_ID = getpass.getpass('Enter Elastic Cloud ID:  ')\n",
    "\n",
    "# Password for the 'elastic' user generated by Elasticsearch\n",
    "ELASTIC_PASSWORD = getpass.getpass('Enter Elastic password:  ')\n",
    "\n",
    "# Create the client instance\n",
    "client = Elasticsearch(\n",
    "    cloud_id=CLOUD_ID,\n",
    "    basic_auth=(\"elastic\", ELASTIC_PASSWORD)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Case 1: Migrate an index with no `text_expansion` field\n",
    "\n",
    "In this example we will see how to upgrade an index which has a simple [ingestion pipeline](https://www.elastic.co/guide/en/elasticsearch/reference/current/ingest.html) configured to use ELSER model `elser_model_2`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Ingestion pipeline \n",
    "\n",
    "We will create a simple pipeline to convert title field values to lowercase and use this ingestion pipeline on our index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client.ingest.put_pipeline(\n",
    "    id=\"ingest-pipeline-lowercase\", \n",
    "    description=\"Ingest pipeline to change title to lowercase\",\n",
    "    processors=[\n",
    "    {\n",
    "      \"lowercase\": {\n",
    "        \"field\": \"title\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create index with mappings\n",
    "\n",
    "Next, we will create a index `movies` with pipeline `ingest-pipeline-lowercase` that we created in previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.indices.create(\n",
    "  index=\"movies\",\n",
    "  settings={\n",
    "      \"index\": {\n",
    "          \"number_of_shards\": 1,\n",
    "          \"number_of_replicas\": 1,\n",
    "          \"default_pipeline\": \"ingest-pipeline-lowercase\"\n",
    "      }\n",
    "  },\n",
    "  mappings={\n",
    "    \"properties\": {\n",
    "      \"plot\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert Documents\n",
    "we are now ready to insert sample dataset of 12 movies to our index `movies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/notebooks/search/movies.json\"\n",
    "response = urlopen(url)\n",
    "\n",
    "# Load the response data into a JSON object\n",
    "data_json = json.loads(response.read())\n",
    "\n",
    "# Prepare the documents to be indexed\n",
    "documents = []\n",
    "for doc in data_json:\n",
    "    documents.append({\n",
    "        \"_index\": \"movies\",\n",
    "        \"_source\": doc,\n",
    "    })\n",
    "\n",
    "# Use helpers.bulk to index\n",
    "helpers.bulk(client, documents)\n",
    "\n",
    "print(\"Done indexing documents into `movies` index!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upgrade index `movies` to use ELSER model\n",
    "\n",
    "**`Note:`** Before you begin upgrading index, make sure you are on 8.11 version in cloud. You can follow these [instructions](https://www.elastic.co/guide/en/machine-learning/current/ml-nlp-ELSER.html#trained-model) to download and deploy trained model in the Kibana UI or using the Dev Tools **Console**.  \n",
    "\n",
    "we are ready to re-index  `movies` to a new index with the ELSER model `.elser_model_2`. As a first step, we have to create new ingestion pipeline and a index to use ELSER model. \n",
    "\n",
    "# Create a new pipeline with ELSER \n",
    "Lets create a new ingestion pipeline with ELSER model `.elser_model_2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.ingest.put_pipeline(\n",
    "    id=\"elser-ingest-pipeline\", \n",
    "    description=\"Ingest pipeline for ELSER\",\n",
    "    processors=[\n",
    "    {\n",
    "      \"inference\": {\n",
    "        \"model_id\": \".elser_model_2\",\n",
    "        \"target_field\": \"ml\",\n",
    "        \"field_map\": {\n",
    "          \"plot\": \"text_field\"\n",
    "        },\n",
    "        \"inference_config\": {\n",
    "          \"text_expansion\": {\n",
    "            \"results_field\": \"tokens\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a index with mappings\n",
    "\n",
    "Next, create an index with [`text_expansion`](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-text-expansion-query.html) query supporting ELSER model and [`rank_features`](https://www.elastic.co/guide/en/elasticsearch/reference/current/rank-features.html) to work with our vectors. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.indices.create(\n",
    "  index=\"elser-movies\",\n",
    "  mappings={\n",
    "    \"properties\": {\n",
    "      \"plot\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"ml.tokens\": {\n",
    "        \"type\": \"rank_features\"\n",
    "      },\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reindex with updated pipeline \n",
    "\n",
    "With the help of [Reindex API](https://elasticsearch-py.readthedocs.io/en/stable/api.html#elasticsearch.Elasticsearch.reindex), we can copy data from old index `movies` and to new index `elser-movies` with  ingestion pipeline set to `elser-ingest-pipeline` .  On success, the index `elser-movies` creates tokens on the `text_expansion` terms that you targeted for ELSER inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.reindex(source={\n",
    "    \"index\": \"movies\"\n",
    "  }, dest={\n",
    "    \"index\": \"elser-movies\",\n",
    "    \"pipeline\":  \"elser-ingest-pipeline\"\n",
    "  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once reindex is complete, inspect a document in the index `elser-movies` and notice that the document now has a additional field `\"ml\": {\"tokens\":...}` with terms that we will be using in to search in our `text_expansion` query. \n",
    "\n",
    "Also note, you can now delete the old index `movies` if you don't need them anymore. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying documents with ELSER \n",
    "\n",
    "Let's try a semantic search on our index with ELSER model `.elser_model_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 6.403748\n",
      "Title: se7en\n",
      "Plot: Two detectives, a rookie and a veteran, hunt a serial killer who uses the seven deadly sins as his motives.\n",
      "\n",
      "Score: 3.6703482\n",
      "Title: the departed\n",
      "Plot: An undercover cop and a mole in the police attempt to identify each other while infiltrating an Irish gang in South Boston.\n",
      "\n",
      "Score: 2.9359207\n",
      "Title: the usual suspects\n",
      "Plot: A sole survivor tells of the twisty events leading up to a horrific gun battle on a boat, which began when five criminals met at a seemingly random police lineup.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.search(\n",
    "    index='elser-movies', \n",
    "    size=3,\n",
    "    query={\n",
    "        \"text_expansion\": {\n",
    "            \"ml.tokens\": {\n",
    "                \"model_id\":\".elser_model_2\",\n",
    "                \"model_text\":\"investigation\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    doc_id = hit['_id']\n",
    "    score = hit['_score']\n",
    "    title = hit['_source']['title']\n",
    "    plot = hit['_source']['plot']\n",
    "    print(f\"Score: {score}\\nTitle: {title}\\nPlot: {plot}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2: Upgrade index with ELSER model to `.elser_model_2`\n",
    "\n",
    "If you already have a index with ELSER model `.elser_model_1` and would like to upgrade to `.elser_model_2`, you can use the Reindex API with ingestion pipeline to use ELSER `.elser_model_2` model.\n",
    "\n",
    "**`Note:`** Before we begin, ensure that you are on Elasticsearch 8.11 version and ELSER model `.elser_model_2` is deployed. You can follow these [instructions](https://www.elastic.co/guide/en/machine-learning/current/ml-nlp-ELSER.html#trained-model) to download and deploy trained model in the Kibana UI or using the Dev Tools **Console**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new ingestion pipeline\n",
    "\n",
    "We will create a pipeline with `.elser_model_2` to enable us with reindexing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.ingest.put_pipeline(\n",
    "    id=\"elser-pipeline-upgrade-demo\", \n",
    "    description=\"Ingest pipeline for ELSER upgrade demo\",\n",
    "    processors=[\n",
    "    {\n",
    "      \"inference\": {\n",
    "        \"model_id\": \".elser_model_2\",\n",
    "        \"target_field\": \"ml\",\n",
    "        \"field_map\": {\n",
    "          \"plot\": \"text_field\"\n",
    "        },\n",
    "        \"inference_config\": {\n",
    "          \"text_expansion\": {\n",
    "            \"results_field\": \"tokens\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new index with mappings\n",
    "We will create  a new index with required mappings supporting ELSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.indices.create(\n",
    "  index=\"elser-upgrade-index-demo\",\n",
    "  mappings={\n",
    "    \"properties\": {\n",
    "      \"plot\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"ml.tokens\": {\n",
    "        \"type\": \"rank_features\"\n",
    "      },\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Reindex API\n",
    "we will use [Reindex API](https://elasticsearch-py.readthedocs.io/en/stable/api.html#elasticsearch.Elasticsearch.reindex) to move data from old index to new index `elser-upgrade-index-demo`. We will be excluding target field `ml` from old index and instead generate new `ml` tokens with `.elser_model_2` while reindexing. \n",
    "\n",
    "**`Note:`** Make sure to replace `my-index` with your index name that you intend to upgrade.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.reindex(source={\n",
    "    \"index\": \"my-index\", # replace with your index name\n",
    "    \"_source\": {\n",
    "      \"excludes\": [\"ml\"]\n",
    "    }}, \n",
    "    dest={\n",
    "    \"index\": \"elser-upgrade-index-demo\",\n",
    "    \"pipeline\":  \"elser-pipeline-upgrade-demo\"\n",
    "  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying your data\n",
    "\n",
    "Once reindexing is complete, you are ready to query on your data and perform semantic search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 3.3168378\n",
      "Title: Fight Club\n",
      "Plot: An insomniac office worker and a devil-may-care soapmaker form an underground fight club that evolves into something much, much more.\n",
      "\n",
      "Score: 1.5777297\n",
      "Title: The Godfather\n",
      "Plot: An organized crime dynasty's aging patriarch transfers control of his clandestine empire to his reluctant son.\n",
      "\n",
      "Score: 1.1162646\n",
      "Title: The Matrix\n",
      "Plot: A computer hacker learns from mysterious rebels about the true nature of his reality and his role in the war against its controllers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.search(\n",
    "    index='elser-upgrade-index-demo', \n",
    "    size=3,\n",
    "    query={\n",
    "        \"text_expansion\": {\n",
    "            \"ml.tokens\": {\n",
    "                \"model_id\":\".elser_model_2\",\n",
    "                \"model_text\":\"child toy\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    doc_id = hit['_id']\n",
    "    score = hit['_score']\n",
    "    title = hit['_source']['title']\n",
    "    plot = hit['_source']['plot']\n",
    "    print(f\"Score: {score}\\nTitle: {title}\\nPlot: {plot}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 3: Upgrade a index with different model to ELSER\n",
    "\n",
    "Now we will see how to move your index which already has generated `embedding` using a different model. \n",
    "\n",
    "Lets consider the index - `blogs` and has generated `text_embedding` using the NLP model `sentence-transformers__all-minilm-l6-v2`. In case you would like know about more how to load a NLP model to an index, follow the steps from our notebook [loading-model-from-hugging-face.ipynb](../integrations/hugging-face/loading-model-from-hugging-face.ipynb)\n",
    "\n",
    "Follow similiar proceedure that we did in previously. \n",
    "1. Create a ingestion pipeline with ELSER model `.elser_model_2`\n",
    "2. Create a index with mappings, with the pipeline we create in step 1\n",
    "3. Reindex, excluding the field with generated embedding from the `blogs` index\n",
    "\n",
    "Before we begin, lets take a look at our index `blogs` and see the mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'blogs': {'aliases': {}, 'mappings': {'properties': {'text_embedding': {'properties': {'is_truncated': {'type': 'boolean'}, 'model_id': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'predicted_value': {'type': 'dense_vector', 'dims': 384, 'index': True, 'similarity': 'l2_norm'}}}, 'title': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}}}, 'settings': {'index': {'routing': {'allocation': {'include': {'_tier_preference': 'data_content'}}}, 'number_of_shards': '1', 'provided_name': 'blogs', 'default_pipeline': 'vectorize_blogs', 'creation_date': '1697033266359', 'number_of_replicas': '1', 'uuid': 'e_SkUcPXT06ZMs1ZbsZfQw', 'version': {'created': '8500003'}}}}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.get(index=\"blogs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the field `text_embedding`, We will have to exclude this field in our new index and generate mapping with `text_expansion` against the field `title` from the `blogs` index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ingestion pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.ingest.put_pipeline(\n",
    "    id=\"elser-pipeline-blogs\", \n",
    "    description=\"Ingest pipeline for ELSER upgrade\",\n",
    "    processors=[\n",
    "    {\n",
    "      \"inference\": {\n",
    "        \"model_id\": \".elser_model_2\",\n",
    "        \"target_field\": \"ml\",\n",
    "        \"field_map\": {\n",
    "          \"title\": \"text_field\"\n",
    "        },\n",
    "        \"inference_config\": {\n",
    "          \"text_expansion\": {\n",
    "            \"results_field\": \"tokens\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create index with mappings\n",
    "\n",
    "Lets create a index `elser-blogs` with mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'elser-blogs'})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.create(\n",
    "  index=\"elser-blogs\",\n",
    "  mappings={\n",
    "    \"properties\": {\n",
    "      \"title\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"ml.tokens\": {\n",
    "        \"type\": \"rank_features\"\n",
    "      },\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reindex API\n",
    "\n",
    "we will use the [Reindex API](https://elasticsearch-py.readthedocs.io/en/stable/api.html#elasticsearch.Elasticsearch.reindex) to copy data and generate `text_expansion` embedding to our new index `elser-blogs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.reindex(source={\n",
    "    \"index\": \"blogs\",\n",
    "    \"_source\": {\n",
    "      \"excludes\": [\"text_embedding\"]\n",
    "    }\n",
    "  }, dest={\n",
    "    \"index\": \"elser-blogs\",\n",
    "    \"pipeline\":  \"elser-pipeline-blogs\"\n",
    "  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying your data\n",
    "Success! Now we can query data on the index `elser-blogs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 27.618645\n",
      "Title: Brewing in Beats: Track network connections\n",
      "Score: 3.8143802\n",
      "Title: Machine Learning for Nginx Logs - Identifying Operational Issues with Your Website\n",
      "Score: 3.3623078\n",
      "Title: Data Visualization For Machine Learning\n"
     ]
    }
   ],
   "source": [
    "response = client.search(\n",
    "    index='elser-blogs', \n",
    "    size=3,\n",
    "    query={\n",
    "        \"text_expansion\": {\n",
    "            \"ml.tokens\": {\n",
    "                \"model_id\":\".elser_model_2\",\n",
    "                \"model_text\":\"Track network connections\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    doc_id = hit['_id']\n",
    "    score = hit['_score']\n",
    "    title = hit['_source']['title']\n",
    "    print(f\"Score: {score}\\nTitle: {title}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
